{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The professionalism, motivation and dedication of my hobby job as referee push me to influence in my research.I hope it will be of benefit in my refereeing and data analyst career. Of course, I hope this code along would be the interest for the reader and coder. The next weekend I'm be called as assitant reff for one match in 2 Division B. Both teams are located in the top classification league fighting for the first position. However, what I supposed to know furthermore the their seeking victory? That's my point, so let's investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "1. [Scrapping](#scrapping)\n",
    "2. [Data cleansing](#data-cleansing)\n",
    "3. [Challengers players: PCA, Scaling, K-means](#challanegers-players:-scaling-pca-k-means)\n",
    "4. [Finding Correlation Between Many Variables](#finding-correlation-between-many-variables)\n",
    "5. [Regression linear between yellows card and minutes played](#regression-linear-between-yellows-card-and-minutes-played)\n",
    "6. [Bar and Density Plot](#bar-and-density-plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping <a name=\"scrapping\"></a>\n",
    "\n",
    "The code and notebooks for my scrapping process,which were done with Selenium and BeatifoulSoup are a part of the repository, and as so I will not detail the process unless there are any requests to do so. \n",
    "\n",
    "I scrapped my data mainly from https://soccerway.com/. Specifically their page on the players stats from the differents teams : Ibiza, Hercules.\n",
    "\n",
    "For further information about the datasets:\n",
    "- Scrapping by Selenium : https://es.soccerway.com/teams/spain/hercules-club-de-futbol/2106/squad/\n",
    "- Scrapping by Selenium : https://es.soccerway.com/teams/spain/se-ibiza-eivissa/9075/squad/\n",
    "- Scrapping by Soup : https://es.soccerway.com/teams/spain/hercules-club-de-futbol/2106/statistics/\n",
    "- Scrapping by Soup : https://es.soccerway.com/teams/spain/ud-ibiza/39898/statistics/\n",
    "- Dataset private provider: Instat\n",
    "\n",
    "In the scrapping code you will initially find which teams you want to search for. Once you have entered the data for both teams correctly, the spider will be created to automatically scrap the statistical data of the players such as the goal probabilities in each interval of minutes during the match of both teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleansing <a name=\"data-cleansing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the data, we import it into python and we will observe how it behaves. It is highly probable that some value is not of the desired type. Therefore, once they are converted into a DataFrame, we start investigating with the elimination of unnecessary columns and renaming those that are most useful for later analysis. Then, the path to follow:\n",
    "1. Convert 'dataset.xls' to DataFrame\n",
    "2. Dropping \n",
    "3. Convert the whole columns int to float as possible\n",
    "4. There're a few object that contain floats and string (because the %), so lets get theses columns and afterwards eliminate the '%' to convert it as float\n",
    "5. Eliminate the class str which contains values with '%' in the df\n",
    "6. There's 0 values in  the weight or height, should convert them by the meaning of the group\n",
    "7. Export this new DF cleaned to Excel because will need it to analyze it in Tableau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challengers players: Scaling, PCA, K-means <a name=\"challanegers-players:-scaling-pca-k-means\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, my objective is to see the relationship between age, height and weight (physical conditions) with variables that indicate the aggressiveness of the team, specifically we will see: Position, Age, Height, Weight, Tickets, Disputes, Fouls, Lost balls, Recovered balls. Later, we will use this DataFrame to apply the normalize technique for its subsequent PCA analysis in terms of correlation, what does this PCA consist of?\n",
    "\n",
    "According Mr.Amat (2017), Principal Component Analysis (PCA) is a statistical method that simplifies the complexity of sample spaces with many dimensions while preserving their information. Suppose that there is a sample with n individuals each with p variables (X1, X2,…, Xp), that is, the sample space has p dimensions. PCA allows finding a number of underlying factors (z <p) that explain roughly the same as the original p variables. Where before p values were needed to characterize each individual, now z values are enough. Each of these z new variables is called a principal component. You will appreciate the fig Ibiza team:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PCA_Ibiza](./images/PCA_home.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the result befores i made by the standardization (or Z-score normalization). This means that the features will be rescaled so that they’ll have the properties of a standard normal distribution with\n",
    "\n",
    "μ=0 and σ=1\n",
    "where μ is the mean (average) and σ is the standard deviation from the mean; standard scores (also called z scores) of the samples are calculated as follows:\n",
    "\n",
    "z=x−μσ\n",
    "\n",
    "Therefor, let's see an example the result before scaling and after to understand the concept:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PCA_Ibiza](./images/scaling_home.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing the features so that they are centered around 0 with a standard deviation of 1 is not only important if we are comparing measurements that have different units, but it is also a general requirement for many machine learning algorithms. Intuitively, we can think of gradient descent as a prominent example (an optimization algorithm often used in logistic regression, SVMs, perceptrons, neural networks etc.), in our case, to plot a k-mean cluster as shown:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PCA_Ibiza](./images/Cluster_home.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Correlation Between Many Variables (Multidimensional Dataset) with Python <a name=\"finding-correlation-between-many-variables\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According Norena (2016), in statistics, dependence or association is any statistical relationship, whether causal or not, between two random variables or bivariate data. Correlation is any of a broad class of statistical relationships involving dependence. As datasets increase the number of variables, finding correlation between those variables becomes difficult, fortunately Python makes this process very easy as in the example below where I will find correlation on a dataset with the following mentioned before chapter. The “corr()” method evaluates the correlation between all the features, then it can be graphed with a color coding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Correlation_Ibiza](./images/Home_team_cor.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this example(Ibiza team correlation), when there is no correlation between 2 variables (when correlation is 0 or near 0) the color is violet. The light color means there is a perfect positive correlation, while the darkest color means there is a perfect negative correlation.\n",
    "When evaluating the correlation between all the features, the The “corr()” method includes the correlation of each feature with itself, which is always 1, so that is why this type of graph always has the red diagonal from the upper left to the lower right. Other than the diagonal, the rest of the squares show correlation between different features, making it really easy to find that “wind” and “arrow” are highly correlated, “height” and “slice” are highly correlated, “nu” and “theta” are have a correlation of about 0.5.\n",
    "Conclusion: the “corr()” is very easy to use and very powerful for the early stages of data analysis (data preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression linear between yellows card and minutes played <a name='regression-linear-between-yellows-card-and-minutes-played'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on Rebecca (2020), the regression models describe the relationship between variables by fitting a line to the observed data. Linear regression models use a straight line, while logistic and nonlinear regression models use a curved line. Regression allows you to estimate how a dependent variable changes as the independent variable(s) change.\n",
    "\n",
    "Simple linear regression is used to estimate the relationship between two quantitative variables. In ma case, we will estimate the reltionship between the minutes played and goals.\n",
    "One exemple would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Linea de regresion Ibiza](./images/r_lineal_home.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar and Density Plot <a name=\"bar-and-density-plot\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame is more than done now, ready for plotting.\n",
    "we plot a bar and density chart for the DataFrame, which returns a Matplotlib Axes object. We use this object to obtain a Matplotlib Figure object that allows us to change the plot’s dimensions. We also change the axes labels afterwards.\n",
    "At the end of the code gist, we export the plot as a PNG file, using the Figure object to get theses results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bar_Plot](./images/barplot_prob_score.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![desnity_plot](./images/density_prob_score.PNG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
